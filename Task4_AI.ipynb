{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9658e442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d68c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "930fb85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (0.31.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from torch>=2.0.0->accelerate) (80.8.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56df742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer (using gpt2-medium for stability)\n",
    "model_name = \"gpt2-medium\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# Set pad_token_id to eos_token_id to avoid warnings\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(prompt, max_new_tokens=200):\n",
    "    \"\"\"\n",
    "    Generates text based on a given prompt.\n",
    "    Args:\n",
    "        prompt (str): The starting text prompt\n",
    "        max_new_tokens (int): Maximum number of new tokens to generate\n",
    "    Returns:\n",
    "        str: Generated text\n",
    "    \"\"\"\n",
    "    # Generate multiple candidates and select the best one\n",
    "    best_text = \"\"\n",
    "    best_score = -float('inf')\n",
    "    num_candidates = 5  \n",
    "\n",
    "    for _ in range(num_candidates):\n",
    "        # Tokenize the input prompt with padding and attention mask\n",
    "        inputs = tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True\n",
    "        ).to(device)\n",
    "        \n",
    "        # Extract input_ids and attention mask\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        # Generate text\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=3,\n",
    "            repetition_penalty=1.8,  # Slightly reduce penalty\n",
    "            do_sample=True,\n",
    "            top_k=50,  # Increase for more diversity\n",
    "            top_p=0.9,  # Increase for more diversity\n",
    "            temperature=0.8,  # Increase for more creativity\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Post-process the generated text\n",
    "        sentences = generated_text.split('. ')\n",
    "        # Remove the prompt from the first sentence\n",
    "        if sentences[0].startswith(prompt):\n",
    "            sentences[0] = sentences[0][len(prompt):].strip()\n",
    "        \n",
    "        # Filter out irrelevant content (relaxed filtering)\n",
    "        relevant_sentences = []\n",
    "        for s in sentences:\n",
    "            if not s.strip():  # Skip empty sentences\n",
    "                continue\n",
    "            # Skip sentences with promotional content, URLs, or off-topic elements\n",
    "            if any(keyword in s.lower() for keyword in [\n",
    "                \"apply now\", \"http\", \"free view\", \"signup\", \"course\", \"program\", \n",
    "                \"we are excited\", \"job offer\", \"game\", \"players\", \"experience points\", \n",
    "                \"quests\", \"cv\", \"blog\", \"i was\"\n",
    "            ]):\n",
    "                continue\n",
    "            relevant_sentences.append(s)\n",
    "        \n",
    "        # Ensure at least 4 sentences (relaxed from 5)\n",
    "        if len(relevant_sentences) < 4:\n",
    "            continue\n",
    "        \n",
    "        # Truncate to 5 sentences for consistency\n",
    "        processed_text = '. '.join(relevant_sentences[:5]) + '.'\n",
    "        \n",
    "        # Score the text based on length (simplified scoring)\n",
    "        score = len(processed_text)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_text = processed_text\n",
    "    \n",
    "    # Fallback: If no good candidate is found, generate a simpler response\n",
    "    if not best_text:\n",
    "        # Use a more guided prompt with relaxed parameters\n",
    "        inputs = tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True\n",
    "        ).to(device)\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=max_new_tokens // 2,  # Shorter for simplicity\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=2,\n",
    "            repetition_penalty=1.5,\n",
    "            do_sample=True,\n",
    "            top_k=30,\n",
    "            top_p=0.95,\n",
    "            temperature=0.6,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        sentences = generated_text.split('. ')\n",
    "        if sentences[0].startswith(prompt):\n",
    "            sentences[0] = sentences[0][len(prompt):].strip()\n",
    "        relevant_sentences = [s for s in sentences if s.strip()][:5]\n",
    "        best_text = '. '.join(relevant_sentences) + '.' if relevant_sentences else \"Unable to generate a response.\"\n",
    "\n",
    "    return best_text\n",
    "\n",
    "# Define prompts with additional context for better guidance\n",
    "prompts = [\n",
    "    \"Describe the future of artificial intelligence and its impact on society. Focus on how AI might improve healthcare, education, and transportation, while addressing potential challenges like job displacement and ethical concerns.\",\n",
    "    \"Tell a story about a distant galaxy where a new species discovers space travel. Include details about the species, their planet, the technology they develop, and their first journey into space, ensuring the story is both epic and fun.\",\n",
    "    \"Provide practical tips for a student to succeed in an AI internship. Offer specific advice on skills to learn, how to collaborate with a team, and how to stand out during the internship.\"\n",
    "]\n",
    "\n",
    "# Define absolute path for output file\n",
    "output_path = r\"C:\\Users\\ASUS\\Desktop\\Codtech-AI-Internship\\Task4\\generated_text.txt.txt\"\n",
    "\n",
    "# Generate and save text\n",
    "with open(output_path, \"w\") as f:\n",
    "    for prompt in prompts:\n",
    "        generated_text = generate_text(prompt)\n",
    "        f.write(f\"Prompt: {prompt}\\n\")\n",
    "        f.write(f\"Generated Text: {generated_text}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
